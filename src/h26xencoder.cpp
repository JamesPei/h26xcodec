
extern "C" {
#include <libavcodec/avcodec.h>
#include <libavutil/avutil.h>
#include <libavutil/frame.h>
#include <libavutil/imgutils.h>
#include <libavutil/mem.h>
#include <libavutil/opt.h>
#include <libavutil/pixfmt.h>
#include <libavutil/rational.h>
#include <libswscale/swscale.h>
}

#include <iostream>
#include <sstream>
#include <h26xcodec/h26xencoder.hpp>

void H26xEncoder::Enable()
{
    createCodec();
    createContext();
    calculateBitsPerPixel();
    createSwsContext();
    createAVFrameAndAVPacket();

    if (avcodec_open2(context_, codec_, nullptr) < 0)
    {
        std::cerr << "Could not open codec" << std::endl;
        std::abort();
    }
    std::cout << Str() << std::endl;
}

void H26xEncoder::createCodec()
{
    // AV_CODEC_ID_H265
    codec_ = const_cast<AVCodec*>(avcodec_find_encoder(codec_id_));
    if (!codec_)
    {
        std::cerr << "Codec with specified id not found" << std::endl;
        std::abort();
    }
}

void H26xEncoder::calculateBitsPerPixel()
{
    auto desc = av_pix_fmt_desc_get(input_pixel_format_);
    if (!desc)
    {
        std::cerr << "Can't get descriptor for pixel format" << std::endl;
        std::abort();
    }

    bits_per_pixel_ = av_get_bits_per_pixel(desc);
}

void H26xEncoder::createContext()
{
    context_ = avcodec_alloc_context3(codec_);
    if (!context_)
    {
        std::cerr << "Can't allocate video codec context" << std::endl;
        std::abort();
    }

    /// Resolution must be a multiple of two
    context_->height = height_;
    context_->width  = width_;

    /// Frames per second
    context_->time_base.num = 1;
    context_->time_base.den = fps_;
    context_->framerate.num = fps_;
    context_->framerate.den = 1;

    /// Only YUV420P for H264|5
    context_->pix_fmt = AV_PIX_FMT_YUV420P;

    /// Key(intra) frame rate
    /// looks like option not works for H265 :(
    context_->gop_size = gop_size_;

    /// P-frames, generated by referencing data from prev and future frames.
    /// [Compression up, CPU usage up]
    /// [use 3/gop]
    context_->max_b_frames = max_b_frames_;

    /// Can be used by a P-frame(predictive, partial frame) to help define a future frame in a compressed video.
    /// [use 3â€“5 ref per P]
    context_->refs = refs_;

    for (auto& option: options_)
    {
        av_opt_set(context_->priv_data, option.first.c_str(), option.second.c_str(), 0);
    }

    ///// Compression efficiency (slower -> better quality + higher cpu%)
    ///// [ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslow]
    ///// Set this option to "ultrafast" is critical for realtime encoding
    //av_opt_set(context_->priv_data, "preset", "ultrafast", 0);

    ///// Compression rate (lower -> higher compression) compress to lower size, makes decoded image more noisy
    ///// Range: [0; 51], sane range: [18; 26]. I used 35 as good compression/quality compromise. This option also
    ///// critical for realtime encoding
    //av_opt_set(context_->priv_data, "crf", "35", 0);

    ///// Change settings based upon the specifics of input
    ///// [psnr, ssim, grain, zerolatency, fastdecode, animation]
    ///// This option is most critical for realtime encoding, because it removes delay between 1th input frame and 1th
    ///// output packet.
    //av_opt_set(context_->priv_data, "tune", "zerolatency", 0);
    
    context_->thread_count = thread_num_;
}

void H26xEncoder::createAVFrameAndAVPacket()
{
    frame_ = av_frame_alloc();
    if (!frame_)
    {
        std::cerr << "Could not allocate video frame" << std::endl;
        std::abort();
    }

    frame_->format = context_->pix_fmt;
    frame_->height = context_->height;
    frame_->width  = context_->width;

    if (av_frame_get_buffer(frame_, 0) < 0)
    {
        std::cerr << "Can't allocate the video frame data" << std::endl;
        std::abort();
    }

    av_init_packet(&packet_);
    packet_.data = nullptr;
    packet_.size = 0;
}

void H26xEncoder::createSwsContext()
{
    if (input_pixel_format_ == AV_PIX_FMT_YUV420P)
    {
        swsContext_ = nullptr;
    }
    else
    {
        swsContext_ = sws_getContext(width_, height_, input_pixel_format_, width_, height_, AV_PIX_FMT_YUV420P, 0,
                                     nullptr, nullptr, nullptr);

        if (!swsContext_)
        {
            std::cerr << "Could not allocate sws context" << std::endl;
            std::abort();
        }
    }
}

void H26xEncoder::fillYuv420pFrame(uint8_t const* content)
{
    int content_size = width_ * height_ * bits_per_pixel_ / 8;

    uint8_t* yData = (uint8_t*)content;
    uint8_t* uData = (uint8_t*)(content + content_size * 2 / 3);
    uint8_t* vData = (uint8_t*)(content + content_size * 5 / 6);

    int ret = av_frame_make_writable(frame_);
    if (ret < 0)
    {
        throw H26xInitFailure("Allocate new buffer(s) for audio or video data Failed");
    }

    // Copy Y, U, V data to the frame
    int planeSize = width_ * height_;
    memcpy(frame_->data[0], yData, planeSize);      // Y plane
    memcpy(frame_->data[1], uData, planeSize / 4);  // U plane
    memcpy(frame_->data[2], vData, planeSize / 4);  // V plane
}

void H26xEncoder::fillRgb24Frame(uint8_t const* data)
{
    // ensure avframe buffer is allocated
    auto ret = av_frame_make_writable(frame_);
    if (ret < 0)
    {
        throw H26xInitFailure("Allocate new buffer(s) for audio or video data Failed");
    }

    uint8_t const* inData[1]     = {data};
    int            inLineSize[1] = {(bits_per_pixel_ * context_->width / 8)};
    sws_scale(swsContext_, inData, inLineSize, 0, context_->height, frame_->data, frame_->linesize);
}

bool H26xEncoder::sendFrame()
{
    if (codec_id_ == AV_CODEC_ID_H265)
    {
        if (gop_size_ >= 0)
        {
            if (gop_size_ == 0 || frame_index_ % gop_size_ == 0)
            {
                frame_->key_frame = 1;
                frame_->pict_type = AVPictureType::AV_PICTURE_TYPE_I;
            }
            else
            {
                frame_->key_frame = 0;
                frame_->pict_type = AVPictureType::AV_PICTURE_TYPE_P;
            }
        }
    }

    frame_index_ = (frame_index_ % fps_) + 1;
    frame_->pts  = frame_index_ % fps_;
    int ret      = avcodec_send_frame(context_, frame_);
    switch (ret)
    {
        case 0:
            return true;
        case AVERROR(EAGAIN):
            return false;
        case AVERROR_EOF:
            return false;
        case AVERROR(EINVAL):
            return false;
        case AVERROR(ENOMEM):
            return false;
        default:
            return false;
    }
}

bool H26xEncoder::recvPacket(std::vector<char>& output)
{
    int ret = avcodec_receive_packet(context_, &packet_);
    switch (ret)
    {
        case 0:
            output.assign(reinterpret_cast<char*>(packet_.data), reinterpret_cast<char*>(packet_.data + packet_.size));
            av_packet_unref(&packet_);
            //ret = avcodec_receive_packet(context_, &packet_);
            //if (ret != AVERROR(EAGAIN))
                // output not available
            //    return false;
            return true;
        case AVERROR(EAGAIN):
            // output not available
            av_packet_unref(&packet_);
            return true;
        case AVERROR_EOF:
            // encoder is fully flushed
            return false;
        case AVERROR(EINVAL):
            // encoder error
            return false;
        default:
            return false;
    }
}

bool H26xEncoder::Encode(uint8_t const* input, std::vector<char>& output)
{
    if (input_pixel_format_ == AV_PIX_FMT_YUV420P)
    {
        fillYuv420pFrame(input);
    }
    else if (input_pixel_format_ == AV_PIX_FMT_RGB24)
    {
        fillRgb24Frame(input);
    }
    sendFrame();
    return recvPacket(output);
}

// void H26xEncoder::flushAll(std::vector<std::string>& tail_frames)
//{
//     avcodec_send_frame(codecContext, nullptr);
//     while (avcodec_receive_packet(codecContext, pkt) == 0)
//     {
//         tail_frames.push_back(std::string(reinterpret_cast<const char*>(pkt->data), pkt->size));
//         av_packet_unref(pkt);
//     }
// }

bool H26xEncoder::Flush(std::vector<char>& output)
{
    avcodec_send_frame(context_, nullptr);
    bool ret = recvPacket(output);
    return ret;
}

std::string H26xEncoder::Str()
{
    std::stringstream ss;
    if (codec_id_ == AV_CODEC_ID_H264)
    {
        ss << "codec_name: H264" << std::endl;
    }
    else if (codec_id_ == AV_CODEC_ID_H265)
    {
        ss << "codec_name: H265" << std::endl;
    }
    else
    {
        ss << "codec_name: UNKNOWN(" << codec_id_ << ")" << std::endl;
    }

    ss << "width: " << width_ << std::endl
       << "height: " << height_ << std::endl
       << "input_pixel_format: " << GetInputPixelFormatString() << std::endl
       << "fps: " << fps_ << std::endl
       << "gop_size: " << gop_size_ << std::endl
       << "max_b_frames: " << max_b_frames_ << std::endl
       << "refs: " << refs_ << std::endl
       << "thread_num: " << thread_num_ << std::endl;
    for (auto& option : options_)
    {
        ss << "option " << option.first << ": " << option.second << std::endl;
    }
    return ss.str();
}


// H26xEncoder::~H26xEncoder()
//{
//     // Flush the encoder
//     avcodec_send_frame(codecContext, nullptr);
//     while (avcodec_receive_packet(codecContext, pkt) == 0)
//     {
//         av_packet_unref(pkt);
//     }
//
//     av_packet_free(&pkt);
//     avcodec_close(codecContext);
//     avcodec_free_context(&codecContext);
//     av_frame_free(&frame);
// }
